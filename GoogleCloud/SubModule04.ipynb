{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![Biofilm image](../images/Biofilm_Website_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submodule #4: Microbiome Community Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The microbial community analysis relies on comparisons of predicted genes, proteins, and functions with existing previously annotated sequences. Functional profiling provides insights into what functions are carried out by a given microbial community and biofilm. Quorum sensing (QS) is one of the key indicators of a bacterial community's behavior. QS is the regulation of gene expression in response to fluctuations in cell-population density. QS bacteria produce and release chemical signaling molecules called autoinducers that increase in concentration as a function of cell density. The presence of QS signaling does not always guarantee biofilm formation, but this phenomenon has proven to be a reliable marker in several phenotype analyses of biofilms, such as those involved in cancer, dental health, medical devices, corrosion, and environmental biofilms.  Here we use the STRING Database and BLAST+ to search for biofilm signatures in our metagenomic samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "*   Understanding biofilms and quorum sensing\n",
    "*   Extracting and manipulating data using Python and pandas\n",
    "*   Querying biological databases (UniProt, STRING) via APIs and BigQuery\n",
    "*   Creating and managing FASTA files\n",
    "*   Utilizing Google Cloud Storage and Batch for data storage and parallel processing\n",
    "*   Running BLAST+ analysis using Nextflow\n",
    "*   Interpreting BLAST results to identify significant hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "*   **Software:** Python 3 (pandas), Nextflow\n",
    "*   **Data:** `pred_metagenome_unstrat.tsv` (PICRUSt2 output)\n",
    "*   **GCP:** Account with BigQuery, Cloud Storage, and Cloud Batch access\n",
    "*   **APIs:** UniProt (public), BigQuery\n",
    "*   **Configuration:**  Correctly configured `Blast/nextflow.config` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Started\n",
    "### Step 5 - Microbial Community and Biofilm Analysis (Google BigQuery and BLAST+): \n",
    "### BigQuery on the STRING Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to carry out our community analysis we will need to gather the protein names of each EC number from our pred_metagenome_unstrat.tsv output that was generated by our PICRUSt2 analysis. To do this we will be using a `for loop` to loop through our file, extracting each EC number and searching it against the Uniprot protein database. All outputs are then added to the **pr_names** list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this can take ~15 min to run, depending on your VM\n",
    "import pandas as pd\n",
    "enzym_list = pd.read_csv('BioMarker_Discovery/picrust2_output/EC_metagenome_out/pred_metagenome_unstrat.tsv',sep='\\t')['function'].values\n",
    "pr_names = []\n",
    "for enzy in enzym_list:\n",
    "    try:\n",
    "        pr_names += list(pd.read_csv('https://rest.uniprot.org/uniprotkb/search?query=(' + enzy +')&format=tsv',sep='\\t')['Entry Name'].values)\n",
    "    except:\n",
    "        print(pd.read_csv('https://rest.uniprot.org/uniprotkb/search?query=(' + enzy +')&format=tsv',sep='\\t')['Entry Name'].values)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can query this list of proteins against the STRING Database that NIH has hosted as a public BigQuery database. An alternative database that can be used is the Biofilms Structural Database (BSD), a collection of structural, mutagenesis, kinetics, and inhibition data to understand the processes involved in biofilm formation.\n",
    "\n",
    "You will notice that we run two queries. The first is to collect the proteins IDs associated with the names we recieved from the Uniprot database. The second query is used to extract the sequences that are associated with the protein IDs. We will need both in order to run these sequences through BLAST+. You can see in the code below that the protein IDs and sequences are stored in a dataframe named **df**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client()\n",
    "# query for protein IDs\n",
    "query = \"\"\"\n",
    "    SELECT * FROM `nih-cl-shared-resources.usd_metagenomics_proteins.proteins_names` where protein_name IN \"\"\" + str(set(pr_names)).replace('{','(').replace('}',')')\n",
    "results = client.query(query)\n",
    "pr_ids = []\n",
    "for row in results:\n",
    "    pr_ids.append(row['protein_id'])\n",
    "pr_ids = tuple(pr_ids)\n",
    "# query for protein sequences\n",
    "query = \"\"\"\n",
    "    SELECT protein_id, sequence FROM `nih-cl-shared-resources.usd_metagenomics_proteins.proteins_sequences` where protein_id IN \"\"\" + str(pr_ids)\n",
    "# Storing the data in a pandas DataFrame\n",
    "df = client.query(query).to_dataframe()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Fasta file (.fa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at our dataframe! We can see that we have a column of numbers (our indexes), protein IDs, and sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view our dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned before, we will be submitting these sequences to BLAST+. The fastest way to parse multiple seuqences is via a fasta file. Fasta files contain two pieces of information: 1) protein IDs and 2) protein sequences. We need to reformat our dataframe so that it has this information in fasta format. You can read more about fasta files [here](https://www.ncbi.nlm.nih.gov/genbank/fastaformat/).\n",
    "\n",
    "In fasta format, each sequence header that contains the protein ID should start with **'>'** symbol. This is the first change we will make.\n",
    "\n",
    "The second change will be to replace any spaces with underscores within the protein_id column using the `replace` command, `lambda` helps to implement this rule to the entire file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['protein_id'] ='>' + df['protein_id'].astype(str)\n",
    "df['protein_id'] = df['protein_id'].apply(lambda x:x.replace(' ','_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view our dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final steps can be done in one command! Notice that our protein IDs and sequences are in one row instead of in separate rows we can us the `.to_csv` command to not only convert our file into a fasta file but to also make any spaces into new lines. The next thing we do is set our indexes and headers to false, this will get rid of the column of numbers and our headers (protein_id and sequences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a fasta file\n",
    "! mkdir Microbiome_Community_Analysis\n",
    "df.to_csv('Microbiome_Community_Analysis/subset_proteins_seqs.fa',sep=\"\\n\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy the Fasta File to Your Own Bucket \n",
    "Finally we can add our file to a Google Cloud Storage Bucket!\n",
    "\n",
    "To create a bucket, use the following command, **be sure to replace `<REPLACE_W_BUCKET_NAME_>` with your own unique bucket name**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env BUCKET=<REPLACE_W_BUCKET_NAME_>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using `%%bash` here to help pass our environement variable to the mb command and other GCP commands. The mb command stands for 'make bucket'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gsutil mb gs://\"${BUCKET}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the `cp` command to copy our subset_proteins_seqs.fa file into our bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gsutil cp Microbiome_Community_Analysis/subset_proteins_seqs.fa gs://${BUCKET}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running BLAST+ through Google Batch with Nextflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BLAST+ (BLASTp) allows us to query multiple sequences through the BLAST database and will then retrieve a collection of hits in our case protein IDs with sequences similar to our collection. The code below runs the following steps:\n",
    "\n",
    "1. Make a custom BLAST database based on our premade fasta file from UniprotKB, this our quorum sensing protein collection (uniprot-download_true_format_fasta_includeIsoform_true-2022.09.23-02.40.31.85.fasta)\n",
    "2. Query our own fasta file against the custom database to see if we have any plausible hits\n",
    "3. Add headers to our output file to better understand the results\n",
    "\n",
    "We will be submitting these commands via Nextflow to Google Batch. This feature allows us to run our BLAST search in parallel by starting up multiple VMs each one running a different job, allowing us to receive our output faster. This is also similar to Kubernetes Engines but unlike Kubernetes Engines after the process is done the VMs will automatically shutdown and be deleted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change the parameters as desired in `Blast/nextflow.config` file\n",
    " - Name of your **Google Cloud project ID** \n",
    " - **Inputs** : \n",
    "     - **INPUT**: Path of the uniprot-download_true_format_fasta_includeIsoform_true-2022.09.23-02.40.31.85.fasta file to create a new BLAST database (this will be automatically pulled from the public bucket) \n",
    "     - **QUERY**: Path to where subset_proteins_seqs.fa was saved in your bucket\n",
    " - **OUTPUT_FILE** : Path to the output directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Netflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mamba create  -n nextflow -c bioconda nextflow=23.10.0 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add nextflow to the PATH\n",
    "import os\n",
    "os.environ['PATH'] = '/opt/conda/envs/nextflow/bin:' + os.environ['PATH'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Nextflow in Google Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the following nextflow job in Google Batch, replace* the bucket name with you created above in `Blast/nextflow.config` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! nextflow run Blast/main.nf -profile gcb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing BLAST Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 style=\"text-align: center;\">BLAST Results Header Names and Descriptions</h4>\n",
    "\n",
    "| Name      | Description |\n",
    "| ----------- | ----------- |\n",
    "| qseqid     |  query or source (e.g., gene) sequence id |\n",
    "| sseqid   | subject  or target (e.g., reference genome) sequence id |\n",
    "| pident     |  percentage of identical matches |\n",
    "| length   | alignment length (sequence overlap) |\n",
    "| mismatch     |  number of mismatches |\n",
    "| gapopen   | number of gap openings |\n",
    "| qstart     |  start of alignment in query |\n",
    "| qend   | end of alignment in query |\n",
    "| sstart     |  start of alignment in subject |\n",
    "| send  | end of alignment in subject |\n",
    "| evalue     |  expect value |\n",
    "| bitscore  | bit score|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were to look at our results as is we would see many more than 30 hits but many can have high e-values and/or have a low percent similarity (pident). To help us evaluate which hits are useful in our analysis we will filter our results based on pident and evalue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results_unfil = pd.read_csv(\"Microbiome_Community_Analysis/proteins_blastp_results.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_unfil.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's filter by percentage of identical matches that equal 100% and sort by the lowest e-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting rows based on condition\n",
    "results_100= results_unfil[results_unfil['pident'] == 100]\n",
    "results_100.sort_values(by=['evalue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see we have several protein IDs that have a 100% match to some of our sequences. Now let's look at their e-values. We want e-values that are very close to 0 becuase it tells us our hit is very significant. That is exactly what we see from our table above. With these results we can conclude that there are biofilm markers within our dataset. To identify these sequences you can look up the seqid in the Uniprot Database: https://www.uniprot.org/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "Run the cell below to check your knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the command below to view the quiz\n",
    "from IPython.display import IFrame\n",
    "IFrame(\"../Quiz/QS15.html\", width=800, height=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this module you learned how to identify community markers relevant to biofilm formation. From our microbiome analysis module (submodule03), you extracted the most relevant markers by cross matching the predictive markers from PICRUSt2 with existing community knowledge bases (e.g. Uniprot, STRING Database). In this submodule, we focused on quorum sensing proteins as the core marker to identify the biofilm signature. It’s important to note that, in some cases quorum sensing is not enough to characterize biofilm formation. The BLAST+ output file allows us to formulate testable hypothesis. For example, in our use case dataset, the highest percentage of identical matches was 100% and our top 5 protein IDs were Q9I4X3, P08987, P13470, O31775, P33883. These show that there are biofilm markers within our dataset, however expert curation and experimental validation is needed to confirm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up\n",
    "\n",
    "Remember to stop your notebook instance when you are done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
